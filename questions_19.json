[
  {
    "question": "A company uses Amazon RDS for MySQL as the database for a critical application. The database workload is mostly writes, with a small number of reads.\nA data engineer notices that the CPU utilization of the DB instance is very high. The high CPU utilization is slowing down the application. The data engineer must reduce the CPU utilization of the DB Instance.\nWhich actions should the data engineer take to meet this requirement? (Choose two.)",
    "options": [
      "Use the Performance Insights feature of Amazon RDS to identify queries that have high CPU utilization. Optimize the problematic queries.",
      "Modify the database schema to include additional tables and indexes.",
      "Reboot the RDS DB instance once each week.",
      "Upgrade to a larger instance size.",
      "Implement caching to reduce the database query load."
    ],
    "answer": [
      "A",
      "D"
    ],
    "type": "multiple"
  },
  {
    "question": "A company stores data in a data lake that is in Amazon S3. Some data that the company stores in the data lake contains personally identifiable information (PII). Multiple user groups need to access the raw data. The company must ensure that user groups can access only the PII that they require.\nWhich solution will meet these requirements with the LEAST effort?",
    "options": [
      "Use Amazon Athena to query the data. Set up AWS Lake Formation and create data filters to establish levels of access for the company's IAM roles. Assign each user to the IAM role that matches the user's PII access requirements.",
      "Use Amazon QuickSight to access the data. Use column-level security features in QuickSight to limit the PII that users can retrieve from Amazon S3 by using Amazon Athena. Define QuickSight access levels based on the PII access requirements of the users.",
      "Build a custom query builder UI that will run Athena queries in the background to access the data. Create user groups in Amazon Cognito. Assign access levels to the user groups based on the PII access requirements of the users.",
      "Create IAM roles that have different levels of granular access. Assign the IAM roles to IAM user groups. Use an identity-based policy to assign access levels to user groups at the column level."
    ],
    "answer": "A",
    "type": "single"
  },
  {
    "question": "A financial company wants to use Amazon Athena to run on-demand SQL queries on a petabyte-scale dataset to support a business intelligence (BI) application. An AWS Glue job that runs during non-business hours updates the dataset once every day. The BI application has a standard data refresh frequency of 1 hour to comply with company policies.\nA data engineer wants to cost optimize the company's use of Amazon Athena without adding any additional infrastructure costs.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      "Configure an Amazon S3 Lifecycle policy to move data to the S3 Glacier Deep Archive storage class after 1 day.",
      "Use the query result reuse feature of Amazon Athena for the SQL queries.",
      "Add an Amazon ElastiCache cluster between the BI application and Athena.",
      "Change the format of the files that are in the dataset to Apache Parquet."
    ],
    "answer": "B",
    "type": "single"
  },
  {
    "question": "A company's data engineer needs to optimize the performance of table SQL queries. The company stores data in an Amazon Redshift cluster. The data engineer cannot increase the size of the cluster because of budget constraints.\nThe company stores the data in multiple tables and loads the data by using the EVEN distribution style. Some tables are hundreds of gigabytes in size. Other tables are less than 10 MB in size.\nWhich solution will meet these requirements?",
    "options": [
      "Keep using the EVEN distribution style for all tables. Specify primary and foreign keys for all tables.",
      "Use the ALL distribution style for large tables. Specify primary and foreign keys for all tables.",
      "Use the ALL distribution style for rarely updated small tables. Specify primary and foreign keys for all tables.",
      "Specify a combination of distribution, sort, and partition keys for all tables."
    ],
    "answer": "C",
    "type": "single"
  },
  {
    "question": "A company receives .csv files that contain physical address data. The data is in columns that have the following names: Door_No, Street_Name, City, and Zip_Code. The company wants to create a single column to store these values in the following format:\n//IMG//<br><br>Which solution will meet this requirement with the LEAST coding effort?",
    "options": [
      "Use AWS Glue DataBrew to read the files. Use the NEST_TO_ARRAY transformation to create the new column.",
      "Use AWS Glue DataBrew to read the files. Use the NEST_TO_MAP transformation to create the new column.",
      "Use AWS Glue DataBrew to read the files. Use the PIVOT transformation to create the new column.",
      "Write a Lambda function in Python to read the files. Use the Python data dictionary type to create the new column."
    ],
    "answer": "B",
    "type": "single"
  },
  {
    "question": "A company receives call logs as Amazon S3 objects that contain sensitive customer information. The company must protect the S3 objects by using encryption. The company must also use encryption keys that only specific employees can access.\nWhich solution will meet these requirements with the LEAST effort?",
    "options": [
      "Use an AWS CloudHSM cluster to store the encryption keys. Configure the process that writes to Amazon S3 to make calls to CloudHSM to encrypt and decrypt the objects. Deploy an IAM policy that restricts access to the CloudHSM cluster.",
      "Use server-side encryption with customer-provided keys (SSE-C) to encrypt the objects that contain customer information. Restrict access to the keys that encrypt the objects.",
      "Use server-side encryption with AWS KMS keys (SSE-KMS) to encrypt the objects that contain customer information. Configure an IAM policy that restricts access to the KMS keys that encrypt the objects.",
      "Use server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the objects that contain customer information. Configure an IAM policy that restricts access to the Amazon S3 managed keys that encrypt the objects."
    ],
    "answer": "C",
    "type": "single"
  },
  {
    "question": "A financial services company stores financial data in Amazon Redshift. A data engineer wants to run real-time queries on the financial data to support a web-based trading application. The data engineer wants to run the queries from within the trading application.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      "Establish WebSocket connections to Amazon Redshift.",
      "Use the Amazon Redshift Data API.",
      "Set up Java Database Connectivity (JDBC) connections to Amazon Redshift.",
      "Store frequently accessed data in Amazon S3. Use Amazon S3 Select to run the queries."
    ],
    "answer": "B",
    "type": "single"
  },
  {
    "question": "A company stores petabytes of data in thousands of Amazon S3 buckets in the S3 Standard storage class. The data supports analytics workloads that have unpredictable and variable data access patterns.\nThe company does not access some data for months. However, the company must be able to retrieve all data within milliseconds. The company needs to optimize S3 storage costs.\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      "Use S3 Storage Lens standard metrics to determine when to move objects to more cost-optimized storage classes. Create S3 Lifecycle policies for the S3 buckets to move objects to cost-optimized storage classes. Continue to refine the S3 Lifecycle policies in the future to optimize storage costs.",
      "Use S3 Storage Lens activity metrics to identify S3 buckets that the company accesses infrequently. Configure S3 Lifecycle rules to move objects from S3 Standard to the S3 Standard-Infrequent Access (S3 Standard-IA) and S3 Glacier storage classes based on the age of the data.",
      "Use S3 Intelligent-Tiering. Activate the Deep Archive Access tier.",
      "Use S3 Intelligent-Tiering. Use the default access tier."
    ],
    "answer": "D",
    "type": "single"
  }
]