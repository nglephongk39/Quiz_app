{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e96208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import openpyxl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f57608",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/phongnl/exam_DEA/json_file/1.json\", \"r\") as f:\n",
    "    data_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d966c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 3,\n",
       " 'choices': {'A': 'Use API calls to access and integrate third-party datasets from AWS Data Exchange.',\n",
       "  'C': 'Use Amazon Kinesis Data Streams to access and integrate third-party datasets from AWS CodeCommit repositories.',\n",
       "  'D': 'Use Amazon Kinesis Data Streams to access and integrate third-party datasets from Amazon Elastic Container Registry (Amazon ECR).',\n",
       "  'B': 'Use API calls to access and integrate third-party datasets from AWS DataSync.'},\n",
       " 'question_text': \"A media company wants to improve a system that recommends media content to customer based on user behavior and preferences. To improve the recommendation system, the company needs to incorporate insights from third-party datasets into the company's existing analytics platform./n/nThe company wants to minimize the effort and time required to incorporate third-party datasets./n/nWhich solution will meet these requirements with the LEAST operational overhead?\",\n",
       " 'answer': 'A'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['pageProps']['questions'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e95fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_questions = []\n",
    "# for i in range(1,43):\n",
    "for i in range(1,3):\n",
    "    with open(rf\"/home/phongnl/exam_DEA/json_file/{i}.json\", \"r\") as f:\n",
    "        data_dict = json.load(f)\n",
    "\n",
    "    data_dict['pageProps']['questions'][0]\n",
    "\n",
    "    questions = data_dict['pageProps']['questions']\n",
    "\n",
    "    for question in questions:\n",
    "        # Question text\n",
    "        question_text = question['question_text']\n",
    "        # print(question_text)\n",
    "        # print(type(question_text))\n",
    "\n",
    "        # Choices\n",
    "        choices = question['choices']\n",
    "        # for key, value in choices.items():\n",
    "        #     print(f\"{key}. {value}\")\n",
    "        # print(choices)\n",
    "        # print(type(choices))\n",
    "\n",
    "        # Correct answer\n",
    "        correct_answer = question['answer']\n",
    "        # print(f\"Correct Answer: {correct_answer}\")\n",
    "        # print(type(correct_answer))\n",
    "\n",
    "        # exam_id = question['exam_id']\n",
    "\n",
    "        row = {\n",
    "            \"question_text\": question_text,\n",
    "            # \"choices\": choices,\n",
    "            \"correct_answer\": correct_answer,\n",
    "            # \"exam_id\": exam_id\n",
    "        }\n",
    "\n",
    "        question_df = pd.DataFrame([row])\n",
    "        for key, val in choices.items():\n",
    "            question_df[key] = val\n",
    "        list_questions.append(question_df)\n",
    "    # break\n",
    "\n",
    "df = pd.concat(list_questions, ignore_index=True)\n",
    "# df.to_excel(\"aws_dea_questions.xlsx\", index=False)\n",
    "# df.to_csv(\"aws_dea_questions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f3b9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phongnl/exam_DEA/uv-project/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "type1 = df[df['correct_answer'].str.len() == 1]\n",
    "type2 = df[df['correct_answer'].str.len() > 1]\n",
    "\n",
    "type1_split = np.array_split(type1, 9)\n",
    "type2_split = np.array_split(type2, 9)\n",
    "\n",
    "file_order = [0] * len(df)\n",
    "for i in range(9):\n",
    "    idx_type1 = type1_split[i].index.tolist()\n",
    "    idx_type2 = type2_split[i].index.tolist()\n",
    "    for idx in idx_type1 + idx_type2:\n",
    "        file_order[idx] = i + 1\n",
    "\n",
    "df['exam'] = file_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247946d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"aws_dea_questions.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8132b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"aws_dea_questions_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df89c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exam_id\n",
       "21    202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['exam_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c86526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['correct_answer'].str.len() > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69879f",
   "metadata": {},
   "source": [
    "# Convert to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c430e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>B</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A data engineer is configuring an AWS Glue job...</td>\n",
       "      <td>D</td>\n",
       "      <td>Update the AWS Glue security group to allow in...</td>\n",
       "      <td>Review the AWS Glue job code to ensure that th...</td>\n",
       "      <td>Verify that the VPC's route table includes inb...</td>\n",
       "      <td>Configure an S3 bucket policy to explicitly gr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A retail company has a customer data hub in an...</td>\n",
       "      <td>B</td>\n",
       "      <td>Create a separate table for each country's cus...</td>\n",
       "      <td>Move the data to AWS Regions that are close to...</td>\n",
       "      <td>Load the data into Amazon Redshift. Create a v...</td>\n",
       "      <td>Register the S3 bucket as a data lake location...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A media company wants to improve a system that...</td>\n",
       "      <td>A</td>\n",
       "      <td>Use API calls to access and integrate third-pa...</td>\n",
       "      <td>Use Amazon Kinesis Data Streams to access and ...</td>\n",
       "      <td>Use Amazon Kinesis Data Streams to access and ...</td>\n",
       "      <td>Use API calls to access and integrate third-pa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A financial company wants to implement a data ...</td>\n",
       "      <td>BE</td>\n",
       "      <td>Use Amazon Aurora for data storage. Use an Ama...</td>\n",
       "      <td>Use AWS Glue DataBrew for centralized data gov...</td>\n",
       "      <td>Use Amazon RDS for data storage. Use Amazon EM...</td>\n",
       "      <td>Use Amazon S3 for data storage. Use Amazon Ath...</td>\n",
       "      <td>Use AWS Lake Formation for centralized data go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A data engineer maintains custom Python script...</td>\n",
       "      <td>B</td>\n",
       "      <td>Store a pointer to the custom Python scripts i...</td>\n",
       "      <td>Store a pointer to the custom Python scripts i...</td>\n",
       "      <td>Assign the same alias to each Lambda function....</td>\n",
       "      <td>Package the custom Python scripts into Lambda ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A data engineer is building a data orchestrati...</td>\n",
       "      <td>C</td>\n",
       "      <td>AWS Data Exchange</td>\n",
       "      <td>Amazon Managed Workflows for Apache Airflow (A...</td>\n",
       "      <td>AWS Glue</td>\n",
       "      <td>Amazon Simple Workflow Service (Amazon SWF)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A gaming company uses a NoSQL database to stor...</td>\n",
       "      <td>C</td>\n",
       "      <td>Amazon Keyspaces (for Apache Cassandra)</td>\n",
       "      <td>Amazon DynamoDB</td>\n",
       "      <td>Amazon Timestream</td>\n",
       "      <td>Amazon DocumentDB (with MongoDB compatibility)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A data engineer creates an AWS Lambda function...</td>\n",
       "      <td>B</td>\n",
       "      <td>Ensure that the trust policy of the Lambda fun...</td>\n",
       "      <td>Ensure that the subnet where the Lambda functi...</td>\n",
       "      <td>Ensure that EventBridge schemas are valid and ...</td>\n",
       "      <td>Ensure that both the IAM role that EventBridge...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A company uses a data lake that is based on an...</td>\n",
       "      <td>B</td>\n",
       "      <td>Use both server-side encryption with AWS KMS k...</td>\n",
       "      <td>Use server-side encryption with customer-provi...</td>\n",
       "      <td>Use server-side encryption with AWS KMS keys (...</td>\n",
       "      <td>Use dual-layer server-side encryption with AWS...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A data engineer notices that Amazon Athena que...</td>\n",
       "      <td>B</td>\n",
       "      <td>Increase the query result limit.</td>\n",
       "      <td>Use federated queries.</td>\n",
       "      <td>Allow users who run the Athena queries to an e...</td>\n",
       "      <td>Configure provisioned capacity for an existing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text correct_answer  \\\n",
       "0  A data engineer is configuring an AWS Glue job...              D   \n",
       "1  A retail company has a customer data hub in an...              B   \n",
       "2  A media company wants to improve a system that...              A   \n",
       "3  A financial company wants to implement a data ...             BE   \n",
       "4  A data engineer maintains custom Python script...              B   \n",
       "5  A data engineer is building a data orchestrati...              C   \n",
       "6  A gaming company uses a NoSQL database to stor...              C   \n",
       "7  A data engineer creates an AWS Lambda function...              B   \n",
       "8  A company uses a data lake that is based on an...              B   \n",
       "9  A data engineer notices that Amazon Athena que...              B   \n",
       "\n",
       "                                                   A  \\\n",
       "0  Update the AWS Glue security group to allow in...   \n",
       "1  Create a separate table for each country's cus...   \n",
       "2  Use API calls to access and integrate third-pa...   \n",
       "3  Use Amazon Aurora for data storage. Use an Ama...   \n",
       "4  Store a pointer to the custom Python scripts i...   \n",
       "5                                  AWS Data Exchange   \n",
       "6            Amazon Keyspaces (for Apache Cassandra)   \n",
       "7  Ensure that the trust policy of the Lambda fun...   \n",
       "8  Use both server-side encryption with AWS KMS k...   \n",
       "9                   Increase the query result limit.   \n",
       "\n",
       "                                                   C  \\\n",
       "0  Review the AWS Glue job code to ensure that th...   \n",
       "1  Move the data to AWS Regions that are close to...   \n",
       "2  Use Amazon Kinesis Data Streams to access and ...   \n",
       "3  Use AWS Glue DataBrew for centralized data gov...   \n",
       "4  Store a pointer to the custom Python scripts i...   \n",
       "5  Amazon Managed Workflows for Apache Airflow (A...   \n",
       "6                                    Amazon DynamoDB   \n",
       "7  Ensure that the subnet where the Lambda functi...   \n",
       "8  Use server-side encryption with customer-provi...   \n",
       "9                             Use federated queries.   \n",
       "\n",
       "                                                   D  \\\n",
       "0  Verify that the VPC's route table includes inb...   \n",
       "1  Load the data into Amazon Redshift. Create a v...   \n",
       "2  Use Amazon Kinesis Data Streams to access and ...   \n",
       "3  Use Amazon RDS for data storage. Use Amazon EM...   \n",
       "4  Assign the same alias to each Lambda function....   \n",
       "5                                           AWS Glue   \n",
       "6                                  Amazon Timestream   \n",
       "7  Ensure that EventBridge schemas are valid and ...   \n",
       "8  Use server-side encryption with AWS KMS keys (...   \n",
       "9  Allow users who run the Athena queries to an e...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  Configure an S3 bucket policy to explicitly gr...   \n",
       "1  Register the S3 bucket as a data lake location...   \n",
       "2  Use API calls to access and integrate third-pa...   \n",
       "3  Use Amazon S3 for data storage. Use Amazon Ath...   \n",
       "4  Package the custom Python scripts into Lambda ...   \n",
       "5        Amazon Simple Workflow Service (Amazon SWF)   \n",
       "6     Amazon DocumentDB (with MongoDB compatibility)   \n",
       "7  Ensure that both the IAM role that EventBridge...   \n",
       "8  Use dual-layer server-side encryption with AWS...   \n",
       "9  Configure provisioned capacity for an existing...   \n",
       "\n",
       "                                                   E  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Use AWS Lake Formation for centralized data go...  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee7f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = []\n",
    "for _, row in df.iterrows():\n",
    "    # Lấy tất cả các cột chứa đáp án (A, B, C, D, E,...)\n",
    "    options_cols = [col for col in row.index if col not in ['question_text', 'correct_answer', 'exam']]\n",
    "    \n",
    "    question_dict = {\n",
    "        \"question\": row['question_text'],\n",
    "        \"options\": [row[col] for col in options_cols if pd.notnull(row[col])],\n",
    "        \"answer\": row['correct_answer'] if len(row['correct_answer']) == 1 else list(row['correct_answer']),\n",
    "        \"type\": \"single\" if len(row['correct_answer']) == 1 else \"multiple\"\n",
    "    }\n",
    "    questions_list.append(question_dict)\n",
    "\n",
    "# Lưu vào file JSON\n",
    "with open('questions_formatted.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(questions_list, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
